{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflectance SMOOTHING ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import array\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from termcolor import colored\n",
    "import time\n",
    "import xarray as xr\n",
    "\n",
    "%reload_ext Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cython functions, modified `ws2dvopt` and `ws2dvoptp` in order to get vcurve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "from cpython.array cimport array, clone\n",
    "from libc.math cimport log, pow, sqrt\n",
    "cimport numpy as np\n",
    "import numpy as np\n",
    "\n",
    "tFloat = np.double\n",
    "ctypedef np.double_t dtype_t\n",
    "\n",
    "\n",
    "cpdef lag1corr(np.ndarray[dtype_t] data1, np.ndarray[dtype_t] data2, double nd):\n",
    "    \"\"\"Calculates Lag-1 autocorrelation.\n",
    "\n",
    "    Adapted from https://stackoverflow.com/a/29194624/5997555\n",
    "\n",
    "    Args:\n",
    "        data1: fist data series\n",
    "        data2: second data series\n",
    "        nd: no-data value (will be exluded from calulation)\n",
    "\n",
    "    Returns:\n",
    "        Lag-1 autocorrelation value\n",
    "    \"\"\"\n",
    "\n",
    "    cdef int M, sub\n",
    "    cdef double sum1, sum2, var_sum1, var_sum2, cross_sum, std1, std2, cross_mean\n",
    "\n",
    "    M = data1.size\n",
    "\n",
    "    sum1 = 0.\n",
    "    sum2 = 0.\n",
    "    sub = 0\n",
    "    for i in range(M):\n",
    "        if data1[i] != nd and data2[i] != nd:\n",
    "            sum1 += data1[i]\n",
    "            sum2 += data2[i]\n",
    "        else:\n",
    "            sub += 1\n",
    "    mean1 = sum1 / (M-sub)\n",
    "    mean2 = sum2 / (M-sub)\n",
    "\n",
    "    var_sum1 = 0.\n",
    "    var_sum2 = 0.\n",
    "    cross_sum = 0.\n",
    "    for i in range(M):\n",
    "        if data1[i] != nd and data2[i] != nd:\n",
    "            var_sum1 += (data1[i] - mean1) ** 2\n",
    "            var_sum2 += (data2[i] - mean2) ** 2\n",
    "            cross_sum += (data1[i] * data2[i])\n",
    "\n",
    "    std1 = (var_sum1 / (M-sub)) ** .5\n",
    "    std2 = (var_sum2 / (M-sub)) ** .5\n",
    "    cross_mean = cross_sum / (M-sub)\n",
    "    return (cross_mean - mean1 * mean2) / (std1 * std2)\n",
    "\n",
    "cpdef ws2d(np.ndarray[dtype_t] y, double lmda, np.ndarray[dtype_t] w):\n",
    "    cdef array dbl_array_template = array('d', [])\n",
    "    cdef int i, i1, i2, m, n\n",
    "    cdef array z, d, c, e\n",
    "\n",
    "    n = y.shape[0]\n",
    "    m = n - 1\n",
    "\n",
    "    z = clone(dbl_array_template, n, zero=False)\n",
    "    d = clone(dbl_array_template, n, zero=False)\n",
    "    c = clone(dbl_array_template, n, zero=False)\n",
    "    e = clone(dbl_array_template, n, zero=False)\n",
    "\n",
    "    d.data.as_doubles[0] = w[0] + lmda\n",
    "    c.data.as_doubles[0] = (-2 * lmda) / d.data.as_doubles[0]\n",
    "    e.data.as_doubles[0] = lmda /d.data.as_doubles[0]\n",
    "    z.data.as_doubles[0] = w[0] * y[0]\n",
    "    d.data.as_doubles[1] = w[1] + 5 * lmda - d.data.as_doubles[0] * (c.data.as_doubles[0] * c.data.as_doubles[0])\n",
    "    c.data.as_doubles[1] = (-4 * lmda - d.data.as_doubles[0] * c.data.as_doubles[0] * e.data.as_doubles[0]) / d.data.as_doubles[1]\n",
    "    e.data.as_doubles[1] =  lmda / d.data.as_doubles[1]\n",
    "    z.data.as_doubles[1] = w[1] * y[1] - c.data.as_doubles[0] * z.data.as_doubles[0]\n",
    "    for i in range(2, m-1):\n",
    "        i1 = i - 1\n",
    "        i2 = i - 2\n",
    "        d.data.as_doubles[i]= w[i] + 6 *  lmda - (c.data.as_doubles[i1] * c.data.as_doubles[i1]) * d.data.as_doubles[i1] - (e.data.as_doubles[i2] * e.data.as_doubles[i2]) * d.data.as_doubles[i2]\n",
    "        c.data.as_doubles[i] = (-4 *  lmda - d.data.as_doubles[i1] * c.data.as_doubles[i1] * e.data.as_doubles[i1])/ d.data.as_doubles[i]\n",
    "        e.data.as_doubles[i] =  lmda / d.data.as_doubles[i]\n",
    "        z.data.as_doubles[i] = w[i] * y[i] - c.data.as_doubles[i1] * z.data.as_doubles[i1] - e.data.as_doubles[i2] * z.data.as_doubles[i2]\n",
    "    i1 = m - 2\n",
    "    i2 = m - 3\n",
    "    d.data.as_doubles[m - 1] = w[m - 1] + 5 *  lmda - (c.data.as_doubles[i1] * c.data.as_doubles[i1]) * d.data.as_doubles[i1] - (e.data.as_doubles[i2] * e.data.as_doubles[i2]) * d.data.as_doubles[i2]\n",
    "    c.data.as_doubles[m - 1] = (-2 *  lmda - d.data.as_doubles[i1] * c.data.as_doubles[i1] * e.data.as_doubles[i1]) / d.data.as_doubles[m - 1]\n",
    "    z.data.as_doubles[m - 1] = w[m - 1] * y[m - 1] - c.data.as_doubles[i1] * z.data.as_doubles[i1] - e.data.as_doubles[i2] * z.data.as_doubles[i2]\n",
    "    i1 = m - 1\n",
    "    i2 = m - 2\n",
    "    d.data.as_doubles[m] = w[m] +  lmda - (c.data.as_doubles[i1] * c.data.as_doubles[i1]) * d.data.as_doubles[i1] - (e.data.as_doubles[i2] * e.data.as_doubles[i2]) * d.data.as_doubles[i2]\n",
    "    z.data.as_doubles[m] = (w[m] * y[m] - c.data.as_doubles[i1] * z.data.as_doubles[i1] - e.data.as_doubles[i2] * z.data.as_doubles[i2]) / d.data.as_doubles[m]\n",
    "    z.data.as_doubles[m - 1] = z.data.as_doubles[m - 1] / d.data.as_doubles[m - 1] - c.data.as_doubles[m - 1] * z.data.as_doubles[m]\n",
    "    for i in range(m-2, -1, -1):\n",
    "        z.data.as_doubles[i] = z.data.as_doubles[i] / d.data.as_doubles[i] - c.data.as_doubles[i] * z.data.as_doubles[i + 1] - e.data.as_doubles[i] * z.data.as_doubles[i + 2]\n",
    "    return z\n",
    "\n",
    "cpdef ws2dp(np.ndarray[dtype_t] y, double lmda, np.ndarray[dtype_t] w, double p):\n",
    "  \"\"\"Whittaker smoother with asymmetric smoothing and fixed lambda (S).\n",
    "\n",
    "  Args:\n",
    "      y: time-series numpy array\n",
    "      l: smoothing parameter lambda (S)\n",
    "      w: weights numpy array\n",
    "      p: \"Envelope\" value\n",
    "\n",
    "  Returns:\n",
    "      Smoothed time-series array z\n",
    "  \"\"\"\n",
    "  cdef array template = array('d', [])\n",
    "  cdef int m, i, j\n",
    "  cdef double y_tmp, z_tmp, p1\n",
    "\n",
    "  m = y.shape[0]\n",
    "  i = 0\n",
    "  j = 0\n",
    "  p1 = 1-p\n",
    "\n",
    "  template = array('d', [])\n",
    "  z = clone(template, m, True)\n",
    "  znew = clone(template, m, True)\n",
    "  wa = clone(template, m, False)\n",
    "  ww = clone(template, m, False)\n",
    "\n",
    "  # Calculate weights\n",
    "\n",
    "  for i in range(10):\n",
    "    for j in range(m):\n",
    "      y_tmp = y[j]\n",
    "      z_tmp = z.data.as_doubles[j]\n",
    "\n",
    "      if y_tmp > z_tmp:\n",
    "        wa.data.as_doubles[j] = p\n",
    "      else:\n",
    "        wa.data.as_doubles[j] = p1\n",
    "      ww.data.as_doubles[j] = w[j] * wa.data.as_doubles[j]\n",
    "\n",
    "    znew[0:m] = _ws2d(y, lmda, ww)\n",
    "    z_tmp = 0.0\n",
    "    j = 0\n",
    "    for j in range(m):\n",
    "      z_tmp += abs(znew.data.as_doubles[j] - z.data.as_doubles[j])\n",
    "\n",
    "    if z_tmp == 0.0:\n",
    "      break\n",
    "\n",
    "    z[0:m]= znew[0:m]\n",
    "\n",
    "  z[0:m] = _ws2d(y, lmda, ww)\n",
    "  return z\n",
    "\n",
    "\n",
    "cdef _ws2d(np.ndarray[dtype_t] y, double lmda, array[double] w):\n",
    "    \"\"\"Internal whittaker function for use in asymmetric smoothing.\n",
    "    Args:\n",
    "      y: time-series numpy array\n",
    "      lmbda: lambda (s) value\n",
    "      w: weights numpy array\n",
    "    Returns:\n",
    "        smoothed time-series array z\n",
    "    \"\"\"\n",
    "\n",
    "    cdef array dbl_array_template = array('d', [])\n",
    "    cdef int i, i1, i2, m, n\n",
    "    cdef array z, d, c, e\n",
    "\n",
    "    n = y.shape[0]\n",
    "    m = n - 1\n",
    "\n",
    "    z = clone(dbl_array_template, n, zero=False)\n",
    "    d = clone(dbl_array_template, n, zero=False)\n",
    "    c = clone(dbl_array_template, n, zero=False)\n",
    "    e = clone(dbl_array_template, n, zero=False)\n",
    "\n",
    "    d.data.as_doubles[0] = w.data.as_doubles[0] + lmda\n",
    "    c.data.as_doubles[0] = (-2 * lmda) / d.data.as_doubles[0]\n",
    "    e.data.as_doubles[0] = lmda /d.data.as_doubles[0]\n",
    "    z.data.as_doubles[0] = w.data.as_doubles[0] * y[0]\n",
    "    d.data.as_doubles[1] = w.data.as_doubles[1] + 5 * lmda - d.data.as_doubles[0] * (c.data.as_doubles[0] * c.data.as_doubles[0])\n",
    "    c.data.as_doubles[1] = (-4 * lmda - d.data.as_doubles[0] * c.data.as_doubles[0] * e.data.as_doubles[0]) / d.data.as_doubles[1]\n",
    "    e.data.as_doubles[1] =  lmda / d.data.as_doubles[1]\n",
    "    z.data.as_doubles[1] = w.data.as_doubles[1] * y[1] - c.data.as_doubles[0] * z.data.as_doubles[0]\n",
    "    for i in range(2, m-1):\n",
    "        i1 = i - 1\n",
    "        i2 = i - 2\n",
    "        d.data.as_doubles[i]= w.data.as_doubles[i] + 6 *  lmda - (c.data.as_doubles[i1] * c.data.as_doubles[i1]) * d.data.as_doubles[i1] - (e.data.as_doubles[i2] * e.data.as_doubles[i2]) * d.data.as_doubles[i2]\n",
    "        c.data.as_doubles[i] = (-4 *  lmda - d.data.as_doubles[i1] * c.data.as_doubles[i1] * e.data.as_doubles[i1])/ d.data.as_doubles[i]\n",
    "        e.data.as_doubles[i] =  lmda / d.data.as_doubles[i]\n",
    "        z.data.as_doubles[i] = w.data.as_doubles[i] * y[i] - c.data.as_doubles[i1] * z.data.as_doubles[i1] - e.data.as_doubles[i2] * z.data.as_doubles[i2]\n",
    "    i1 = m - 2\n",
    "    i2 = m - 3\n",
    "    d.data.as_doubles[m - 1] = w.data.as_doubles[m - 1] + 5 *  lmda - (c.data.as_doubles[i1] * c.data.as_doubles[i1]) * d.data.as_doubles[i1] - (e.data.as_doubles[i2] * e.data.as_doubles[i2]) * d.data.as_doubles[i2]\n",
    "    c.data.as_doubles[m - 1] = (-2 *  lmda - d.data.as_doubles[i1] * c.data.as_doubles[i1] * e.data.as_doubles[i1]) / d.data.as_doubles[m - 1]\n",
    "    z.data.as_doubles[m - 1] = w.data.as_doubles[m - 1] * y[m - 1] - c.data.as_doubles[i1] * z.data.as_doubles[i1] - e.data.as_doubles[i2] * z.data.as_doubles[i2]\n",
    "    i1 = m - 1\n",
    "    i2 = m - 2\n",
    "    d.data.as_doubles[m] = w.data.as_doubles[m] +  lmda - (c.data.as_doubles[i1] * c.data.as_doubles[i1]) * d.data.as_doubles[i1] - (e.data.as_doubles[i2] * e.data.as_doubles[i2]) * d.data.as_doubles[i2]\n",
    "    z.data.as_doubles[m] = (w.data.as_doubles[m] * y[m] - c.data.as_doubles[i1] * z.data.as_doubles[i1] - e.data.as_doubles[i2] * z.data.as_doubles[i2]) / d.data.as_doubles[m]\n",
    "    z.data.as_doubles[m - 1] = z.data.as_doubles[m - 1] / d.data.as_doubles[m - 1] - c.data.as_doubles[m - 1] * z.data.as_doubles[m]\n",
    "    for i in range(m-2, -1, -1):\n",
    "        z.data.as_doubles[i] = z.data.as_doubles[i] / d.data.as_doubles[i] - c.data.as_doubles[i] * z.data.as_doubles[i + 1] - e.data.as_doubles[i] * z.data.as_doubles[i + 2]\n",
    "    return z\n",
    "\n",
    "\n",
    "cpdef ws2doptv(np.ndarray[dtype_t] y, np.ndarray[dtype_t] w, array[double] llas):\n",
    "    \"\"\"Whittaker smoother with normal V-curve optimization of lambda (S).\n",
    "    Args:\n",
    "        y: time-series numpy array\n",
    "        w: weights numpy array\n",
    "        llas: array with lambda values to iterate (S-range)\n",
    "    Returns:\n",
    "        Smoothed time-series array z and optimized lambda (S) value lopt\n",
    "    \"\"\"\n",
    "    cdef array template = array('d', [])\n",
    "    cdef array fits, pens, diff1, lamids, v, z\n",
    "    cdef int m, m1, m2, nl, nl1, lix, i, k\n",
    "    cdef double w_tmp, y_tmp, z_tmp, z2, llastep, f1, f2, p1, p2, l, l1, l2, vmin, lopt\n",
    "\n",
    "    m = y.shape[0]\n",
    "    m1 = m - 1\n",
    "    m2 = m - 2\n",
    "    nl = len(llas)\n",
    "    nl1 = nl - 1\n",
    "    i = 0\n",
    "    k = 0\n",
    "\n",
    "    template = array('d', [])\n",
    "\n",
    "    fits = clone(template, nl, True)\n",
    "    pens = clone(template, nl, True)\n",
    "    z = clone(template, m, False)\n",
    "    diff1 = clone(template, m1, True)\n",
    "    lamids = clone(template, nl1, False)\n",
    "    v = clone(template, nl1, False)\n",
    "\n",
    "    # Compute v-curve\n",
    "    for lix in range(nl):\n",
    "        l = pow(10,llas.data.as_doubles[lix])\n",
    "        z[0:m] = ws2d(y, l, w)\n",
    "        for i in range(m):\n",
    "            w_tmp = w[i]\n",
    "            y_tmp = y[i]\n",
    "            z_tmp = z.data.as_doubles[i]\n",
    "            fits.data.as_doubles[lix] += pow(w_tmp * (y_tmp - z_tmp),2) \n",
    "        fits.data.as_doubles[lix] = log(fits.data.as_doubles[lix])\n",
    "\n",
    "        for i in range(m1):\n",
    "            z_tmp = z.data.as_doubles[i]\n",
    "            z2 = z.data.as_doubles[i+1]\n",
    "            diff1.data.as_doubles[i] = z2 - z_tmp\n",
    "        for i in range(m2):\n",
    "            z_tmp = diff1.data.as_doubles[i]\n",
    "            z2 = diff1.data.as_doubles[i+1]\n",
    "            pens.data.as_doubles[lix] += pow(z2 - z_tmp,2)\n",
    "        pens.data.as_doubles[lix] = log(pens.data.as_doubles[lix])\n",
    "\n",
    "    # Construct v-curve\n",
    "    llastep = llas[1] - llas[0]\n",
    "\n",
    "    for i in range(nl1):\n",
    "        l1 = llas.data.as_doubles[i]\n",
    "        l2 = llas.data.as_doubles[i+1]\n",
    "        f1 = fits.data.as_doubles[i]\n",
    "        f2 = fits.data.as_doubles[i+1]\n",
    "        p1 = pens.data.as_doubles[i]\n",
    "        p2 = pens.data.as_doubles[i+1]\n",
    "        v.data.as_doubles[i] = sqrt(pow(f2 - f1,2) + pow(p2 - p1,2)) / (log(10) * llastep)\n",
    "        lamids.data.as_doubles[i] = (l1+l2) / 2\n",
    "\n",
    "    vmin = v.data.as_doubles[k]\n",
    "    for i in range(1, nl1):\n",
    "        if v.data.as_doubles[i] < vmin:\n",
    "            vmin = v.data.as_doubles[i]\n",
    "            k = i\n",
    "\n",
    "    lopt = pow(10, lamids.data.as_doubles[k])\n",
    "\n",
    "    z[0:m] = ws2d(y, lopt, w)\n",
    "\n",
    "    return z, lopt, v, lamids\n",
    "\n",
    "\n",
    "\n",
    "cpdef ws2doptvp(np.ndarray[dtype_t] y, np.ndarray[dtype_t] w, array[double] llas, double p):\n",
    "    \"\"\"Whittaker smoother with asymmetric V-curve optimization of lambda (S).\n",
    "    Args:\n",
    "        y: time-series numpy array\n",
    "        w: weights numpy array\n",
    "        llas: array with lambda values to iterate (S-range)\n",
    "        p: \"Envelope\" value\n",
    "    Returns:\n",
    "        Smoothed time-series array z and optimized lambda (S) value lopt\n",
    "    \"\"\"\n",
    "    cdef array template = array('d', [])\n",
    "    cdef array fits, pens, diff1, lamids, v, z\n",
    "    cdef int m, m1, m2, nl, nl1, lix, i, j, k\n",
    "    cdef double w_tmp, y_tmp, z_tmp, z2, llastep, fit1, fit2, pen1, pen2, l, l1, l2, vmin, lopt, p1\n",
    "\n",
    "    m = y.shape[0]\n",
    "    m1 = m - 1\n",
    "    m2 = m - 2\n",
    "    nl = len(llas)\n",
    "    nl1 = nl - 1\n",
    "    i = 0\n",
    "    k = 0\n",
    "    j = 0\n",
    "    p1 = 1-p\n",
    "\n",
    "    template = array('d', [])\n",
    "    fits = clone(template, nl, True)\n",
    "    pens = clone(template, nl, True)\n",
    "    z = clone(template, m, True)\n",
    "    znew = clone(template, m, True)\n",
    "    diff1 = clone(template, m1, True)\n",
    "    lamids = clone(template, nl1, False)\n",
    "    v = clone(template, nl1, False)\n",
    "    wa = clone(template, m, False)\n",
    "    ww = clone(template, m, False)\n",
    "\n",
    "    # Compute v-curve\n",
    "    for lix in range(nl):\n",
    "        l = pow(10,llas.data.as_doubles[lix])\n",
    "\n",
    "        for i in range(10):\n",
    "          for j in range(m):\n",
    "            y_tmp = y[j]\n",
    "            z_tmp = z.data.as_doubles[j]\n",
    "            if y_tmp > z_tmp:\n",
    "              wa.data.as_doubles[j] = p\n",
    "            else:\n",
    "              wa.data.as_doubles[j] = p1\n",
    "            ww.data.as_doubles[j] = w[j] * wa.data.as_doubles[j]\n",
    "\n",
    "          znew[0:m] = _ws2d(y, l, ww)\n",
    "          z_tmp = 0.0\n",
    "          j = 0\n",
    "          for j in range(m):\n",
    "            z_tmp += abs(znew.data.as_doubles[j] - z.data.as_doubles[j])\n",
    "\n",
    "          if z_tmp == 0.0:\n",
    "            break\n",
    "\n",
    "          z[0:m]= znew[0:m]\n",
    "\n",
    "        for i in range(m):\n",
    "            w_tmp = w[i]\n",
    "            y_tmp = y[i]\n",
    "            z_tmp = z.data.as_doubles[i]\n",
    "            fits.data.as_doubles[lix] += pow(w_tmp * (y_tmp - z_tmp),2)\n",
    "        fits.data.as_doubles[lix] = log(fits.data.as_doubles[lix])\n",
    "\n",
    "        for i in range(m1):\n",
    "            z_tmp = z.data.as_doubles[i]\n",
    "            z2 = z.data.as_doubles[i+1]\n",
    "            diff1.data.as_doubles[i] = z2 - z_tmp\n",
    "        for i in range(m2):\n",
    "            z_tmp = diff1.data.as_doubles[i]\n",
    "            z2 = diff1.data.as_doubles[i+1]\n",
    "            pens.data.as_doubles[lix] += pow(z2 - z_tmp,2)\n",
    "        pens.data.as_doubles[lix] = log(pens.data.as_doubles[lix])\n",
    "\n",
    "    # Construct v-curve\n",
    "    llastep = llas[1] - llas[0]\n",
    "\n",
    "    for i in range(nl1):\n",
    "        l1 = llas.data.as_doubles[i]\n",
    "        l2 = llas.data.as_doubles[i+1]\n",
    "        fit1 = fits.data.as_doubles[i]\n",
    "        fit2 = fits.data.as_doubles[i+1]\n",
    "        pen1 = pens.data.as_doubles[i]\n",
    "        pen2 = pens.data.as_doubles[i+1]\n",
    "        v.data.as_doubles[i] = sqrt(pow(fit2 - fit1,2) + pow(pen2 - pen1,2)) / (log(10) * llastep)\n",
    "        lamids.data.as_doubles[i] = (l1+l2) / 2\n",
    "\n",
    "    vmin = v.data.as_doubles[k]\n",
    "    for i in range(1, nl1):\n",
    "        if v.data.as_doubles[i] < vmin:\n",
    "            vmin = v.data.as_doubles[i]\n",
    "            k = i\n",
    "\n",
    "    lopt = pow(10, lamids.data.as_doubles[k])\n",
    "\n",
    "    del z\n",
    "    z = clone(template, m, True)\n",
    "\n",
    "    for i in range(10):\n",
    "      for j in range(m):\n",
    "        y_tmp = y[j]\n",
    "        z_tmp = z.data.as_doubles[j]\n",
    "\n",
    "        if y_tmp > z_tmp:\n",
    "          wa.data.as_doubles[j] = p\n",
    "        else:\n",
    "          wa.data.as_doubles[j] = p1\n",
    "        ww.data.as_doubles[j] = w[j] * wa.data.as_doubles[j]\n",
    "\n",
    "      znew[0:m] = _ws2d(y, lopt, ww)\n",
    "      z_tmp = 0.0\n",
    "      j = 0\n",
    "      for j in range(m):\n",
    "        z_tmp += abs(znew.data.as_doubles[j] - z.data.as_doubles[j])\n",
    "\n",
    "      if z_tmp == 0.0:\n",
    "        break\n",
    "\n",
    "      z[0:m]= znew[0:m]\n",
    "\n",
    "    z[0:m] = _ws2d(y, lopt, ww)\n",
    "    \n",
    "    return z, lopt, v, lamids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def fromstring(x):\n",
    "    \n",
    "    '''Converts string to datetime object'''\n",
    "    \n",
    "    try:\n",
    "        d = datetime.datetime.strptime(x, '%d/%m/%Y').date()\n",
    "    except:\n",
    "        d = datetime.datetime.strptime(x, '%Y-%m-%d').date()\n",
    "        \n",
    "    return d\n",
    "\n",
    "def fromjulian(x):\n",
    "    \n",
    "    '''Converts julian to datetime object'''\n",
    "\n",
    "    return datetime.datetime.strptime(x, '%Y%j').date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract time series functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def select_satellite(sat: str, ndvi_MD: tuple, ref_MD: tuple):\n",
    "    \n",
    "    (ndvi_MOD, ndvi_MYD, ndvi_MXD) = ndvi_MD\n",
    "    (ref_MOD, ref_MYD, ref_MXD) = ref_MD\n",
    "    \n",
    "    if (sat == 'MYD'):\n",
    "        ndvi_df = ndvi_MYD\n",
    "        ref_df = ref_MYD\n",
    "    elif (sat == 'MOD'):\n",
    "        ndvi_df = ndvi_MOD\n",
    "        ref_df = ref_MOD\n",
    "    else:\n",
    "        ndvi_df = ndvi_MXD\n",
    "        ref_df = ref_MXD\n",
    "        \n",
    "    return (ndvi_df, ref_df)\n",
    "\n",
    "def ndvi_extract_ts(df: pd.DataFrame, location: str, date_begin: datetime.date, date_end: datetime.date):\n",
    "    \n",
    "    y = df['NDVI'].loc[location].values\n",
    "\n",
    "    dts = df['Date'].loc[location].values\n",
    "    \n",
    "    c_dts = df['Composite_date'].loc[location].values\n",
    "\n",
    "    same_c = df['Same_composite'].loc[location].values\n",
    "    \n",
    "    #Crop to date range\n",
    "    date_range = np.all([dts>=date_begin, dts<=date_end], axis=0)\n",
    "    y = y[date_range]\n",
    "    dts = dts[date_range]\n",
    "    c_dts = c_dts[date_range]\n",
    "    same_c = same_c[date_range]\n",
    "    \n",
    "    return (y, dts, c_dts, same_c)\n",
    "\n",
    "def ref_extract_ts(df: pd.DataFrame, location: str, date_begin: datetime.date, date_end: datetime.date):\n",
    "    \n",
    "    y1 = df['B1'].loc[location].values\n",
    "    y2 = df['B2'].loc[location].values\n",
    "\n",
    "    dts = df['Date'].loc[location].values\n",
    "    \n",
    "    c_dts = df['Composite_date'].loc[location].values\n",
    "    \n",
    "    #Crop to date range\n",
    "    date_range = np.all([dts>=date_begin, dts<=date_end], axis=0)\n",
    "    y1 = y1[date_range]\n",
    "    y2 = y2[date_range]\n",
    "    dts = dts[date_range]\n",
    "    c_dts = c_dts[date_range]\n",
    "    \n",
    "    return (y1, y2, dts, c_dts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derive NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def compute_ndvi_float(b1: float, b2:float):\n",
    "    \n",
    "    if ((b2 + b1) == 0):\n",
    "        ndvi = 0\n",
    "    else:\n",
    "        ndvi = (b2 - b1)/(b2 + b1)\n",
    "        \n",
    "    return ndvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def compute_ndvi_array(ref_b1: np.ndarray, ref_b2: np.ndarray):\n",
    "    \n",
    "    # derive NDVI\n",
    "    ndvi = []\n",
    "    for i in range(len(ref_b1)):\n",
    "        ndvi.append(compute_ndvi_float(ref_b1[i], ref_b2[i]))\n",
    "    \n",
    "    return np.array(ndvi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smoothing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndvi_smoothing(y: np.ndarray, pvalue: float, nopval: bool, lrange: np.ndarray, nd: int):\n",
    "    \n",
    "     # create weights\n",
    "    w = np.array((y!=nd)*1,dtype='double')\n",
    "\n",
    "    # apply whittaker filter with V-curve\n",
    "    if (nopval):\n",
    "        z, lopt, vcurve, l = ws2doptv(y, w, array.array('d',lrange))\n",
    "    else:\n",
    "        z, lopt, vcurve, l = ws2doptvp(y, w, array.array('d',lrange), pvalue)\n",
    "    \n",
    "    return (z, lopt, vcurve, l)\n",
    "\n",
    "\n",
    "def ref_smoothing(y1: np.ndarray, y2: np.ndarray, pvalue: float, nopval: bool, lrange: np.ndarray, nd: int):\n",
    "\n",
    "     # create weights\n",
    "    w1 = np.array((y1!=nd)*1,dtype='double')\n",
    "    w2 = np.array((y2!=nd)*1,dtype='double')\n",
    "\n",
    "    # apply whittaker filter with V-curve\n",
    "    if (nopval):\n",
    "        z1, lopt1, vcurve1, l1 = ws2doptv(y1, w1, array.array('d',lrange))\n",
    "        z2, lopt2, vcurve2, l2 = ws2doptv(y2, w2, array.array('d',lrange))\n",
    "    else:\n",
    "        z1, lopt1, vcurve1, l1 = ws2doptvp(y1, w1, array.array('d',lrange), pvalue)\n",
    "        z2, lopt2, vcurve2, l2 = ws2doptvp(y2, w2, array.array('d',lrange), pvalue)\n",
    "    \n",
    "    return (z1, z2, lopt1, lopt2, vcurve1, vcurve2, l1, l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print and Plot functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def print_info(location: str, latlon: dict, lagCorr1: float, lagCorr2: float):\n",
    "    \n",
    "    print('\\033[1m' + 'Selected Point: ', location, '\\033[0m')\n",
    "    print('(Lat, Lon) =', latlon[location] )\n",
    "    print('\\n')\n",
    "    \n",
    "    print('LagCorr of NDVI: ', round(lagCorr1,3))\n",
    "    print('LagCorr of Reflectance: ', round(lagCorr2,3))\n",
    "    print('\\n')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def plot_all(A0: bool, B1:bool, B2:bool,\n",
    "             ndvi: np.ndarray, derived_ndvi: np.ndarray, \n",
    "             ndvi_z0: np.ndarray, ndvi_z1: np.ndarray, ndvi_z2: np.ndarray,\n",
    "             ndvi_dts: np.ndarray, ref_c_dts: np.ndarray,\n",
    "             nd: float, \n",
    "             yauto: bool, ylimits: tuple):\n",
    "    \n",
    "    \n",
    "    #replace nd by nan\n",
    "    ndvi_nan = ndvi.copy()\n",
    "    ndvi_nan[ndvi_nan == nd] = np.nan\n",
    "    \n",
    "    derived_ndvi_nan = derived_ndvi.copy()\n",
    "    derived_ndvi_nan[derived_ndvi_nan == nd] = np.nan\n",
    "    \n",
    "    plt.figure(figsize=(20,5))\n",
    "    \n",
    "    #raw values\n",
    "    plt.plot(ndvi_dts, ndvi_nan, color = 'lightgrey', marker = 'o', alpha = 0.5)\n",
    "    plt.plot(ref_c_dts, derived_ndvi_nan, color = 'grey', marker = 'o', alpha = 0.5)\n",
    "    \n",
    "    #smoothed values\n",
    "    A = [A0, B1, B2]\n",
    "    xA = [ndvi_dts, ref_c_dts, ref_c_dts]\n",
    "    z = [ndvi_z0, ndvi_z1, ndvi_z2]\n",
    "    col = ['b', 'r', 'g']\n",
    "    label = ['A0', 'B1', 'B2']\n",
    "    leg = ['raw ndvi', 'raw derived NDVI']\n",
    "    \n",
    "    for i,a in enumerate(A):\n",
    "        if a:\n",
    "            plt.plot(xA[i], z[i], color = col[i], alpha = 0.5)\n",
    "            leg.append(label[i])\n",
    "\n",
    "    \n",
    "    if not(yauto):\n",
    "        plt.ylim(ylimits)\n",
    "    \n",
    "    plt.xlabel('Date', fontsize=15)\n",
    "    plt.ylabel('NDVI', fontsize=15)\n",
    "    plt.legend(leg, fontsize=17, loc = 'lower right')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "def plot_vcurve(A0: bool, B1:bool, B2:bool,\n",
    "                     ndvi_l0: np.ndarray, ndvi_l1: np.ndarray, ref_l1: np.ndarray, ref_l2: np.ndarray,\n",
    "                     ndvi_vcurve0: np.ndarray, ndvi_vcurve1: np.ndarray, ref_vcurve1: np.ndarray, ref_vcurve2: np.ndarray, \n",
    "                     ndvi_lopt0: float, ndvi_lopt1: float, ref_lopt1: float, ref_lopt2: float):\n",
    "    \n",
    "    plt.figure(figsize=(20,10))\n",
    "    \n",
    "    \n",
    "    A = [A0, B1, B2, B2]\n",
    "    xA = [ndvi_l0, ndvi_l1, ref_l1, ref_l2]\n",
    "    v = [ndvi_vcurve0, ndvi_vcurve1, ref_vcurve1, ref_vcurve2]\n",
    "    lopt = [ndvi_lopt0, ndvi_lopt1, ref_lopt1, ref_lopt2]\n",
    "    col = ['blue', 'red', 'green', 'darkgreen']\n",
    "    band = ['','','(band 1) ', '(band 2) ']\n",
    "    leg = []\n",
    "    \n",
    "    for i,a in enumerate(A):\n",
    "        if a:\n",
    "            plt.plot(xA[i], v[i], color = col[i], alpha = 0.5, marker = 'o')\n",
    "            leg.append('lopt ' + band[i] + str(round(np.log10(lopt[i]),2)))\n",
    "            \n",
    "    for i,a in enumerate(A):\n",
    "        if a:\n",
    "            plt.axvline(x = np.log10(lopt[i]), ls = '--', color = col[i])\n",
    "\n",
    "    plt.xlabel('log10(l)', fontsize=15)\n",
    "    plt.ylabel('V', fontsize=15)\n",
    "    plt.title('V-curves', fontsize=23)\n",
    "    plt.legend(leg, fontsize=17, loc = 'lower right')\n",
    "    plt.show()\n",
    "            \n",
    "    \n",
    "def plot_year(A0: bool, B1:bool, B2:bool,\n",
    "              year: int, month: int, \n",
    "              ndvi: np.ndarray, derived_ndvi: np.ndarray, \n",
    "              ndvi_z0: np.ndarray, ndvi_z1: np.ndarray, ndvi_z2: np.ndarray, \n",
    "              ndvi_dts: np.ndarray, ref_c_dts: np.ndarray, \n",
    "              nd: float, \n",
    "              yauto: bool, ylimits: tuple):\n",
    "\n",
    "    \n",
    "    #replace nd by nan\n",
    "    ndvi_nan = ndvi.copy()\n",
    "    ndvi_nan[ndvi_nan == nd] = np.nan\n",
    "    \n",
    "    derived_ndvi_nan = derived_ndvi.copy()\n",
    "    derived_ndvi_nan[derived_ndvi_nan == nd] = np.nan\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(20,10))\n",
    "\n",
    "    # Cropping time series to year\n",
    "    year_index = np.all([ndvi_dts>=datetime.date(year,month,1), ndvi_dts<datetime.date(year+1,month,1)], axis=0)\n",
    "    ndvi_dts = ndvi_dts[year_index]\n",
    "    ndvi_nan = ndvi_nan[year_index]\n",
    "    ndvi_z0 = np.array(ndvi_z0)[year_index]\n",
    "\n",
    "    year_index2 = np.all([ref_c_dts>=datetime.date(year,month,1), ref_c_dts<datetime.date(year+1,month,1)], axis=0)\n",
    "    ref_c_dts = ref_c_dts[year_index2]\n",
    "    derived_ndvi_nan = derived_ndvi_nan[year_index2]\n",
    "    ndvi_z1 = np.array(ndvi_z1)[year_index2]\n",
    "    ndvi_z2 = np.array(ndvi_z2)[year_index2]\n",
    "        \n",
    "    \n",
    "    \n",
    "    #raw values\n",
    "    plt.plot(ndvi_dts, ndvi_nan, color = 'lightgrey', marker = 'o', alpha = 0.5)\n",
    "    plt.plot(ref_c_dts, derived_ndvi_nan, color = 'grey', marker = 'o', alpha = 0.5)\n",
    "    \n",
    "    \n",
    "    A = [A0, B1, B2]\n",
    "    xA = [ndvi_dts, ref_c_dts, ref_c_dts]\n",
    "    z = [ndvi_z0, ndvi_z1, ndvi_z2]\n",
    "    col = ['b', 'r', 'g']\n",
    "    label = ['A0', 'B1', 'B2']\n",
    "    leg = ['raw NDVI', 'raw derived NDVI']\n",
    "    \n",
    "    for i,a in enumerate(A):\n",
    "        if a:\n",
    "            plt.plot(xA[i], z[i], color = col[i], alpha = 0.5)\n",
    "            leg.append(label[i])\n",
    "    \n",
    "    if not(yauto):\n",
    "        plt.ylim(ylimits)\n",
    "\n",
    "    plt.xlabel('Date', fontsize=15)\n",
    "    plt.ylabel('NDVI', fontsize=15)\n",
    "    plt.legend(leg, fontsize=15, loc = 'lower right')\n",
    "    plt.title('Year ' + str(year), fontsize = 20)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(A0: bool, B1:bool, B2:bool,\n",
    "              ndvi_MD: tuple, ref_MD:tuple,\n",
    "              location: str, latlon: dict, satellite: str, \n",
    "              pvalue:float, nopval: bool, \n",
    "              lrange1: tuple, lrange2: tuple, step: float, \n",
    "              nd: int, \n",
    "              date_begin: datetime.date, date_end: datetime.date, \n",
    "              year: int, month: int,\n",
    "              yauto: bool, ylimits: tuple):\n",
    "    \n",
    "    lrange1 = np.arange(lrange1[0],lrange1[1], step)\n",
    "    lrange2 = np.arange(lrange2[0],lrange2[1], step)\n",
    "    \n",
    "    #extract time series\n",
    "    ndvi_df, ref_df = select_satellite(satellite, ndvi_MD, ref_MD)\n",
    "    (ndvi, ndvi_dts, ndvi_c_dts, ndvi_same_c) = ndvi_extract_ts(ndvi_df, location, date_begin, date_end) \n",
    "    (ref_b1, ref_b2, ref_dts, ref_c_dts) = ref_extract_ts(ref_df, location, date_begin, date_end)\n",
    "    \n",
    "    #Deriving NDVI from raw reflectance\n",
    "    derived_ndvi = compute_ndvi_array(ref_b1, ref_b2)\n",
    "    \n",
    "    #smoothing\n",
    "    (ndvi_z0, ndvi_lopt0, ndvi_vcurve0, ndvi_l0) = ndvi_smoothing(ndvi, pvalue, nopval, lrange1, nd)\n",
    "    (ndvi_z1, ndvi_lopt1, ndvi_vcurve1, ndvi_l1) = ndvi_smoothing(derived_ndvi, pvalue, nopval, lrange1, nd)\n",
    "    (ref_z1, ref_z2, ref_lopt1, ref_lopt2, ref_vcurve1, ref_vcurve2, ref_l1, ref_l2) = ref_smoothing(ref_b1, ref_b2, pvalue, nopval, lrange2, nd)\n",
    "    \n",
    "    #deriving NDVI from smoothed reflectance\n",
    "    ndvi_z2 = compute_ndvi_array(ref_z1, ref_z2)\n",
    "\n",
    "    #lagCorr\n",
    "    lagCorr1 = lag1corr(np.array(ndvi[0:len(ndvi)-1]), np.array(ndvi[1:]), nd)\n",
    "    lagCorr2 = lag1corr(np.array(derived_ndvi[0:len(derived_ndvi)-1]), np.array(derived_ndvi[1:]), nd)\n",
    "    \n",
    "    #Prints and plots\n",
    "    print_info(location, latlon, lagCorr1, lagCorr2)\n",
    "    plot_all(A0, B1, B2, ndvi, derived_ndvi, ndvi_z0, ndvi_z1, ndvi_z2, ndvi_dts, ref_c_dts, nd, yauto, ylimits)\n",
    "    plot_year(A0, B1, B2, year, month, ndvi, derived_ndvi, ndvi_z0, ndvi_z1, ndvi_z2, ndvi_dts, ref_c_dts, nd, yauto, ylimits)\n",
    "    plot_vcurve(A0, B1, B2, ndvi_l0, ndvi_l1, ref_l1, ref_l2, ndvi_vcurve0, ndvi_vcurve1, ref_vcurve1, ref_vcurve2, ndvi_lopt0, ndvi_lopt1, ref_lopt1, ref_lopt2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NDVI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ndvi_nd = -3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# loading ndvi_MOD data from csv\n",
    "ndvi_MOD = pd.read_csv(\n",
    "    'data/MOD13A2-MOD13A2-006-results.csv', \n",
    "    index_col=0, \n",
    "    usecols = ['ID', \n",
    "               'Date', \n",
    "               'MOD13A2_006__1_km_16_days_NDVI', \n",
    "               'MOD13A2_006__1_km_16_days_composite_day_of_the_year'],\n",
    "    dtype = {'MOD13A2_006__1_km_16_days_composite_day_of_the_year': int})\n",
    "\n",
    "\n",
    "#renaming the columns\n",
    "ndvi_MOD = ndvi_MOD.rename(columns={\"MOD13A2_006__1_km_16_days_NDVI\": \"NDVI\", \n",
    "                        \"MOD13A2_006__1_km_16_days_composite_day_of_the_year\": \"Composite_date\"})\n",
    "\n",
    "\n",
    "# Convert string Date to datetime.date\n",
    "ndvi_MOD['Date'] = ndvi_MOD['Date'].apply(fromstring)\n",
    "\n",
    "\n",
    "# Convert composite_date from julian to datetime\n",
    "# Add a True/False column to keep track of the values with the same composite_date\n",
    "\n",
    "compo = []\n",
    "same_compo = []\n",
    "\n",
    "for i in range(len(ndvi_MOD)):\n",
    "    \n",
    "    d = ndvi_MOD['Date'][i]\n",
    "    c = ndvi_MOD['Composite_date'][i]\n",
    "    \n",
    "    if c != -1:    \n",
    "        if (d.month == 12) and (c<20):\n",
    "            compo.append(fromjulian(str(d.year+1)+str(c)))\n",
    "        else:\n",
    "            compo.append(fromjulian(str(d.year)+str(c)))\n",
    "    else:\n",
    "        # nodata so we don't care about the date\n",
    "        compo.append(d)\n",
    "    \n",
    "    if (i==0):\n",
    "        same_compo.append(False)\n",
    "    elif (compo[i]==compo[i-1]):\n",
    "        same_compo.append(True)\n",
    "    else:\n",
    "        same_compo.append(False)\n",
    "            \n",
    "ndvi_MOD['Composite_date'] = compo   \n",
    "ndvi_MOD['Same_composite'] = same_compo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# loading MYD data from csv\n",
    "ndvi_MYD = pd.read_csv(\n",
    "    'data/MYD13A2-MYD13A2-006-results.csv', \n",
    "    index_col=0, \n",
    "    usecols = ['ID', \n",
    "               'Date', \n",
    "               'MYD13A2_006__1_km_16_days_NDVI', \n",
    "               'MYD13A2_006__1_km_16_days_composite_day_of_the_year'],\n",
    "    dtype = {'MYD13A2_006__1_km_16_days_composite_day_of_the_year': int})\n",
    "\n",
    "\n",
    "#renaming the columns\n",
    "ndvi_MYD = ndvi_MYD.rename(columns={\"MYD13A2_006__1_km_16_days_NDVI\": \"NDVI\", \n",
    "                        \"MYD13A2_006__1_km_16_days_composite_day_of_the_year\": \"Composite_date\"})\n",
    "\n",
    "\n",
    "# Convert string Date to datetime.date\n",
    "ndvi_MYD['Date'] = ndvi_MYD['Date'].apply(fromstring)\n",
    "\n",
    "\n",
    "# Convert composite_date from julian to datetime\n",
    "# Add a True/False column to keep track of the values with the same composite_date\n",
    "\n",
    "compo = []\n",
    "same_compo = []\n",
    "\n",
    "for i in range(len(ndvi_MYD)):\n",
    "    \n",
    "    d = ndvi_MYD['Date'][i]\n",
    "    c = ndvi_MYD['Composite_date'][i]\n",
    "    \n",
    "    if c != -1:    \n",
    "        if (d.month == 12) and (c<20):\n",
    "            compo.append(fromjulian(str(d.year+1)+str(c)))\n",
    "        else:\n",
    "            compo.append(fromjulian(str(d.year)+str(c)))\n",
    "    else:\n",
    "        # nodata so we don't care about the date\n",
    "        compo.append(d)\n",
    "    \n",
    "    if (i==0):\n",
    "        same_compo.append(False)\n",
    "    elif (compo[i]==compo[i-1]):\n",
    "        same_compo.append(True)\n",
    "    else:\n",
    "        same_compo.append(False)\n",
    "            \n",
    "ndvi_MYD['Composite_date'] = compo   \n",
    "ndvi_MYD['Same_composite'] = same_compo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#creating MXD\n",
    "\n",
    "#changing the index to numbers\n",
    "number_index1 = pd.Index(range(0,2*len(ndvi_MYD),2))\n",
    "number_index2 = pd.Index(range(1,2*len(ndvi_MYD)+1,2))\n",
    "\n",
    "ndvi_MYD_nb = ndvi_MYD.set_index(number_index1)\n",
    "ndvi_MYD_nb['ID'] = ndvi_MYD.index\n",
    "ndvi_MOD_nb = ndvi_MOD.set_index(number_index2)\n",
    "ndvi_MOD_nb['ID'] = ndvi_MOD.index\n",
    "\n",
    "\n",
    "#concatenating and resetting ID as index\n",
    "ndvi_MXD = pd.concat([ndvi_MYD_nb, ndvi_MOD_nb]).sort_index()\n",
    "ndvi_MXD = ndvi_MXD.set_index('ID')\n",
    "\n",
    "#re-run same_composite\n",
    "same_compo = []\n",
    "for i in range(len(ndvi_MXD)):\n",
    "    if (i==0 or i==1):\n",
    "        same_compo.append(False)\n",
    "    elif (ndvi_MXD['Composite_date'][i]==ndvi_MXD['Composite_date'][i-1] or ndvi_MXD['Composite_date'][i]==ndvi_MXD['Composite_date'][i-2]):\n",
    "        same_compo.append(True)\n",
    "    else:\n",
    "        same_compo.append(False)\n",
    "              \n",
    "ndvi_MXD['Same_composite'] = same_compo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reflectance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# loading ndvi_MOD data from csv\n",
    "ref_MOD = pd.read_csv(\n",
    "    'data/MOD09A1-MOD09A1-006-results.csv', \n",
    "    index_col=0, \n",
    "    usecols = ['ID', \n",
    "               'Date', \n",
    "               'MOD09A1_006_sur_refl_b01', \n",
    "               'MOD09A1_006_sur_refl_b02',\n",
    "               'MOD09A1_006_sur_refl_day_of_year'],\n",
    "     dtype = {'MOD09A1_006_sur_refl_day_of_year': int})\n",
    "\n",
    "\n",
    "#renaming the columns\n",
    "ref_MOD = ref_MOD.rename(columns={\"MOD09A1_006_sur_refl_b01\": \"B1\", \n",
    "                        \"MOD09A1_006_sur_refl_b02\": \"B2\",\n",
    "                        'MOD09A1_006_sur_refl_day_of_year': 'Composite_date'})\n",
    "\n",
    "\n",
    "# Convert string Date to datetime.date\n",
    "ref_MOD['Date'] = ref_MOD['Date'].apply(fromstring)\n",
    "\n",
    "#Cropping to right dates\n",
    "a = (ref_MOD['Date']>datetime.date(2002,7,4)).values\n",
    "ref_MOD = ref_MOD[a]\n",
    "\n",
    "# Convert composite_date from julian to datetime\n",
    "# Add a True/False column to keep track of the values with the same composite_date\n",
    "\n",
    "compo = []\n",
    "same_compo = []\n",
    "\n",
    "for i in range(len(ref_MOD)):\n",
    "    \n",
    "    d = ref_MOD['Date'][i]\n",
    "    c = ref_MOD['Composite_date'][i]\n",
    "    \n",
    "    if c != 65535:    #because nd is 65535\n",
    "        if (d.month == 12) and (c<20):\n",
    "            compo.append(fromjulian(str(d.year+1)+str(c)))\n",
    "        else:\n",
    "            compo.append(fromjulian(str(d.year)+str(c)))\n",
    "    else:\n",
    "        # nodata so we don't care about the date\n",
    "        compo.append(d)\n",
    "    \n",
    "    if (i==0):\n",
    "        same_compo.append(True)\n",
    "    elif (compo[i]==compo[i-1]):\n",
    "        same_compo.append(False)\n",
    "    else:\n",
    "        same_compo.append(True)\n",
    "            \n",
    "ref_MOD['Composite_date'] = compo   \n",
    "ref_MOD = ref_MOD[same_compo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# loading ndvi_MOD data from csv\n",
    "ref_MYD = pd.read_csv(\n",
    "    'data/MYD09A1-MYD09A1-006-results.csv', \n",
    "    index_col=0, \n",
    "    usecols = ['ID', \n",
    "               'Date', \n",
    "               'MYD09A1_006_sur_refl_b01', \n",
    "               'MYD09A1_006_sur_refl_b02',\n",
    "               'MYD09A1_006_sur_refl_day_of_year'],\n",
    "     dtype = {'MYD09A1_006_sur_refl_day_of_year': int})\n",
    "\n",
    "\n",
    "#renaming the columns\n",
    "ref_MYD = ref_MYD.rename(columns={\"MYD09A1_006_sur_refl_b01\": \"B1\", \n",
    "                        \"MYD09A1_006_sur_refl_b02\": \"B2\",\n",
    "                        'MYD09A1_006_sur_refl_day_of_year': 'Composite_date'})\n",
    "\n",
    "\n",
    "# Convert string Date to datetime.date\n",
    "ref_MYD['Date'] = ref_MYD['Date'].apply(fromstring)\n",
    "\n",
    "# Convert composite_date from julian to datetime\n",
    "# Add a True/False column to keep track of the values with the same composite_date\n",
    "\n",
    "compo = []\n",
    "same_compo = []\n",
    "\n",
    "for i in range(len(ref_MYD)):\n",
    "    \n",
    "    d = ref_MYD['Date'][i]\n",
    "    c = ref_MYD['Composite_date'][i]\n",
    "    \n",
    "    if c != 65535:    #because nd is 65535    \n",
    "        if (d.month == 12) and (c<20):\n",
    "            compo.append(fromjulian(str(d.year+1)+str(c)))\n",
    "        else:\n",
    "            compo.append(fromjulian(str(d.year)+str(c)))\n",
    "    else:\n",
    "        # nodata so we don't care about the date\n",
    "        compo.append(d)\n",
    "    \n",
    "    if (i==0):\n",
    "        same_compo.append(True)\n",
    "    elif (compo[i]==compo[i-1]):\n",
    "        same_compo.append(False)\n",
    "    else:\n",
    "        same_compo.append(True)\n",
    "            \n",
    "ref_MYD['Composite_date'] = compo   \n",
    "ref_MYD = ref_MYD[same_compo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Creating MXD\n",
    "\n",
    "ref_MXD = pd.DataFrame()\n",
    "\n",
    "# Blend MOD and MYD as function of composite_date for each location\n",
    "locations = sorted(list(set(ref_MYD.index)))\n",
    "for l in locations:\n",
    "    \n",
    "    MOD = ref_MOD.loc[l]\n",
    "    MOD = MOD.reset_index()\n",
    "    MOD = MOD.set_index('Composite_date')\n",
    "    \n",
    "    MYD = ref_MYD.loc[l]\n",
    "    MYD = MYD.reset_index()\n",
    "    MYD = MYD.set_index('Composite_date')\n",
    "    \n",
    "    MXD = pd.concat([MOD, MYD]).sort_index()\n",
    "    MXD = MXD.reset_index()\n",
    "    MXD = MXD.set_index('ID')\n",
    "    \n",
    "    ref_MXD = pd.concat([ref_MXD, MXD])\n",
    "\n",
    "# Remove values with same composite_date (keep max value)\n",
    "same_compo = []\n",
    "for i in range(len(ref_MXD)):    \n",
    "    if (i==0):\n",
    "        same_compo.append(True)\n",
    "    elif (ref_MXD['Composite_date'][i]==ref_MXD['Composite_date'][i-1]):\n",
    "        if compute_ndvi_float(ref_MXD['B1'][i-1],ref_MXD['B2'][i-1]) > compute_ndvi_float(ref_MXD['B1'][i],ref_MXD['B2'][i]): \n",
    "            same_compo.pop()\n",
    "            same_compo.append(False)\n",
    "            same_compo.append(True)\n",
    "        else:\n",
    "            same_compo.append(False)\n",
    "    else:\n",
    "        same_compo.append(True)\n",
    "        \n",
    "ref_MXD = ref_MXD[same_compo]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ID lat lon**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Creating lat lon dictionnary\n",
    "\n",
    "latlon = {}\n",
    "\n",
    "pd_latlon = pd.read_csv(\n",
    "    'data/MYD13A2-MYD13A2-006-results.csv', \n",
    "    index_col=0, \n",
    "    usecols = ['ID', \n",
    "               'Latitude', \n",
    "               'Longitude'])\n",
    "\n",
    "dict_index = set(pd_latlon.index)\n",
    "\n",
    "for location in dict_index:\n",
    "    latlon[location] = (round(pd_latlon.loc[location]['Latitude'][0],3), round(pd_latlon.loc[location]['Longitude'][0],3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
